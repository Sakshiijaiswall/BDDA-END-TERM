{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb4af5fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/pyspark/sql/context.py:125: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import * #Import spark types\n",
    "from pyspark.sql.functions import * #Import spark functions\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession #Import the spark session\n",
    "from pyspark import SparkContext #Create a spark context\n",
    "from pyspark.sql import SQLContext #Create an SQL context\n",
    "\n",
    "from pyspark.ml.feature import Tokenizer #Used to tokenize the tweet data\n",
    "from pyspark.ml.feature import CountVectorizer #Used to make the data into vectors\n",
    "from pyspark.ml import Pipeline #Build a pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier #The chosen classifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator #Metrics\n",
    "\n",
    "conf = pyspark.SparkConf().setAll([('spark.executor.memory', '16g'), ('spark.executor.cores', '1'), ('spark.cores.max', '1'), ('spark.driver.memory','16g')])\n",
    "sc = SparkContext.getOrCreate(conf = conf) #Initialize the spark context\n",
    "sqlContext = SQLContext.getOrCreate(sc) #Create an SQL Context\n",
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate() #Make a spark session\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b128252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+---------+\n",
      "|            UserName|          ScreenName|            Location|             TweetAt|       OriginalTweet|Sentiment|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+---------+\n",
      "|                3799|               48751|              London|          16-03-2020|@MeNyrbie @Phil_G...|  Neutral|\n",
      "|                3800|               48752|                  UK|          16-03-2020|advice Talk to yo...| Positive|\n",
      "|                3801|               48753|           Vagabonds|          16-03-2020|Coronavirus Austr...| Positive|\n",
      "|                3802|               48754|                null|          16-03-2020|My food stock is ...|     null|\n",
      "|              PLEASE|         don't panic| THERE WILL BE EN...|                null|                null|     null|\n",
      "|           Stay calm|          stay safe.|                null|                null|                null|     null|\n",
      "|#COVID19france #C...|            Positive|                null|                null|                null|     null|\n",
      "|                3803|               48755|                null|          16-03-2020|Me, ready to go a...|     null|\n",
      "|Not because I'm p...| but because my f...|          but please| don't panic. It ...|                null|     null|\n",
      "|#CoronavirusFranc...|  Extremely Negative|                null|                null|                null|     null|\n",
      "|                3804|               48756|ÜT: 36.319708,-82...|          16-03-2020|As news of the re...| Positive|\n",
      "|                3805|               48757|35.926541,-78.753267|          16-03-2020|\"Cashier at groce...| Positive|\n",
      "|                3806|               48758|             Austria|          16-03-2020|Was at the superm...|     null|\n",
      "|#toiletpapercrisi...|             Neutral|                null|                null|                null|     null|\n",
      "|                3807|               48759|     Atlanta, GA USA|          16-03-2020|Due to COVID-19 o...| Positive|\n",
      "|                3808|               48760|    BHAVNAGAR,GUJRAT|          16-03-2020|For corona preven...| Negative|\n",
      "|                3809|               48761|      Makati, Manila|          16-03-2020|All month there h...|  Neutral|\n",
      "|                3810|               48762|Pitt Meadows, BC,...|          16-03-2020|Due to the Covid-...|     null|\n",
      "|The wait time may...| particularly bee...|                null|                null|                null|     null|\n",
      "|We thank you for ...|  Extremely Positive|                null|                null|                null|     null|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#tweets = spark.read.csv(\"Corona_NLP_train.csv\", inferSchema = True, header = False) #Read in the data\n",
    "#tweets.show(10) #Show the first 10 columns\n",
    "\n",
    "#download the file from hadoop filesystem\n",
    "#!hadoop fs -get /data/Corona_NLP_train.csv .\n",
    "file_path=\"Corona_NLP_train.csv\"\n",
    "\n",
    "tweets= sqlContext.read.format('com.databricks.spark.csv').options(header='true', inferschema='true').load(file_path)\n",
    "tweets.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f738c58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+--------+-------+-------------+---------+\n",
      "|UserName|ScreenName|Location|TweetAt|OriginalTweet|Sentiment|\n",
      "+--------+----------+--------+-------+-------------+---------+\n",
      "|       4|     12417|   33799|  26311|        26663|    39429|\n",
      "+--------+----------+--------+-------+-------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#calculate the null values in column\n",
    "tweets.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in tweets.columns]).show() #Check for null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbd60188",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the rows have null values\n",
    "tweets=tweets.na.drop(how=\"any\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c832945c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+--------------------+----------+--------------------+------------------+\n",
      "|UserName|ScreenName|            Location|   TweetAt|       OriginalTweet|         Sentiment|\n",
      "+--------+----------+--------------------+----------+--------------------+------------------+\n",
      "|    3799|     48751|              London|16-03-2020|@MeNyrbie @Phil_G...|           Neutral|\n",
      "|    3800|     48752|                  UK|16-03-2020|advice Talk to yo...|          Positive|\n",
      "|    3801|     48753|           Vagabonds|16-03-2020|Coronavirus Austr...|          Positive|\n",
      "|    3804|     48756|ÜT: 36.319708,-82...|16-03-2020|As news of the re...|          Positive|\n",
      "|    3805|     48757|35.926541,-78.753267|16-03-2020|\"Cashier at groce...|          Positive|\n",
      "|    3807|     48759|     Atlanta, GA USA|16-03-2020|Due to COVID-19 o...|          Positive|\n",
      "|    3808|     48760|    BHAVNAGAR,GUJRAT|16-03-2020|For corona preven...|          Negative|\n",
      "|    3809|     48761|      Makati, Manila|16-03-2020|All month there h...|           Neutral|\n",
      "|    3811|     48763|          Horningsea|16-03-2020|#horningsea is a ...|Extremely Positive|\n",
      "|    3818|     48770|          Denver, CO|16-03-2020|For those who are...|          Positive|\n",
      "|    3819|     48771|southampton soxx xxx|16-03-2020|with 100  nations...|Extremely Negative|\n",
      "|    3823|     48775|    Downstage centre|16-03-2020|@10DowningStreet ...|          Negative|\n",
      "|    3824|     48776|              London|16-03-2020|UK #consumer poll...|Extremely Positive|\n",
      "|    3825|     48777|      Ketchum, Idaho|16-03-2020|In preparation fo...|          Negative|\n",
      "|    3826|     48778| Everywhere You Are!|16-03-2020|This morning I te...|Extremely Negative|\n",
      "|    3834|     48786|             Sverige|16-03-2020|Went to the super...|           Neutral|\n",
      "|    3836|     48788|              Canada|16-03-2020|Worried about the...|          Positive|\n",
      "|    3838|     48790|       United States|16-03-2020|Now I can go to t...|          Positive|\n",
      "|    3841|     48793|             Houston|16-03-2020|CHECK VIDEO ?? ht...|Extremely Negative|\n",
      "|    3842|     48794|Vancouver, Britis...|16-03-2020|Breaking Story: O...|           Neutral|\n",
      "+--------+----------+--------------------+----------+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweets.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b83e762b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.ml.feature import StringIndexer\n",
    "# indexers = [StringIndexer(inputCol=\"Sentiment\", outputCol=\"Target\").fit(df)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6364b10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline = Pipeline(stages=indexers)\n",
    "# df_r = pipeline.fit(tweets).transform(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e18664a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_r.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3268347d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#decode_map = {0: \"Neutral\", 1: \"Positive\",1:\"Extremely Positive\",2:\"Extremely Negative\",2:\"Negative\"}\n",
    "#maping the column with particular data\n",
    "\n",
    "def decode_sentiment(label):\n",
    "    if label == \"Positive\" or label == \"Extremely Positive\":\n",
    "        return \"Positive\"\n",
    "    elif label == \"Negative\" or label == \"Extremely Negative\":\n",
    "        return \"Negative\"\n",
    "    else:\n",
    "        return \"Neutral\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6100564",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making udf\n",
    "stringNumber = udf(lambda m: decode_sentiment(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df3017a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets.select('Sentiment').distinct().collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b2109c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply udf on tweets column\n",
    "tweets=tweets.withColumn(\"target_Sentiment\", stringNumber(\"Sentiment\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65aa1921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+--------+----------+--------------------+---------+----------------+\n",
      "|UserName|ScreenName|Location|   TweetAt|       OriginalTweet|Sentiment|target_Sentiment|\n",
      "+--------+----------+--------+----------+--------------------+---------+----------------+\n",
      "|    3799|     48751|  London|16-03-2020|@MeNyrbie @Phil_G...|  Neutral|         Neutral|\n",
      "|    3800|     48752|      UK|16-03-2020|advice Talk to yo...| Positive|        Positive|\n",
      "+--------+----------+--------+----------+--------------------+---------+----------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweets.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a8f225a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#droping column have no meaning or useless column\n",
    "#data preprocessing\n",
    "\n",
    "drop_list =[\"UserName\",\"ScreenName\",\"Location\",\"TweetAt\",\"Sentiment\"]\n",
    "data = tweets.select([column for column in tweets.columns if column not in drop_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d412d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------+\n",
      "|       OriginalTweet|target_Sentiment|\n",
      "+--------------------+----------------+\n",
      "|@MeNyrbie @Phil_G...|         Neutral|\n",
      "|advice Talk to yo...|        Positive|\n",
      "|Coronavirus Austr...|        Positive|\n",
      "|As news of the re...|        Positive|\n",
      "|\"Cashier at groce...|        Positive|\n",
      "|Due to COVID-19 o...|        Positive|\n",
      "|For corona preven...|        Negative|\n",
      "|All month there h...|         Neutral|\n",
      "|#horningsea is a ...|        Positive|\n",
      "|For those who are...|        Positive|\n",
      "|with 100  nations...|        Negative|\n",
      "|@10DowningStreet ...|        Negative|\n",
      "|UK #consumer poll...|        Positive|\n",
      "|In preparation fo...|        Negative|\n",
      "|This morning I te...|        Negative|\n",
      "|Went to the super...|         Neutral|\n",
      "|Worried about the...|        Positive|\n",
      "|Now I can go to t...|        Positive|\n",
      "|CHECK VIDEO ?? ht...|        Negative|\n",
      "|Breaking Story: O...|         Neutral|\n",
      "+--------------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4bdd3845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------------+\n",
      "|OriginalTweet|target_Sentiment|\n",
      "+-------------+----------------+\n",
      "|            0|               0|\n",
      "+-------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "data.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in data.columns]).show() #Check for null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e511457",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_set, val_set, test_set) = data.randomSplit([0.98, 0.01, 0.01], seed = 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3271a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the pipeline for feature extraction\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "# tokenizing the data\n",
    "tokenizer = Tokenizer(inputCol=\"OriginalTweet\", outputCol=\"words\")\n",
    "\n",
    "# Creating an instance of the TF-IDF\n",
    "hashtf = HashingTF(numFeatures=2**16, inputCol=\"words\", outputCol='tf')\n",
    "idf = IDF(inputCol='tf', outputCol=\"features\", minDocFreq=5) #minDocFreq: remove sparse terms\n",
    "\n",
    "# to convert string target to index target\n",
    "label_stringIdx = StringIndexer(inputCol = \"target_Sentiment\", outputCol = \"label\")\n",
    "\n",
    "# the complete pipeline: sequence of various stages\n",
    "pipeline = Pipeline(stages=[tokenizer, hashtf, idf, label_stringIdx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd51f6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating data piping \n",
    "pipelineFit = pipeline.fit(train_set)\n",
    "train_df = pipelineFit.transform(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13896275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------+--------------------+--------------------+--------------------+-----+\n",
      "|       OriginalTweet|target_Sentiment|               words|                  tf|            features|label|\n",
      "+--------------------+----------------+--------------------+--------------------+--------------------+-----+\n",
      "|    Police office...|        Positive|[, , , , police, ...|(65536,[1434,1511...|(65536,[1434,1511...|  0.0|\n",
      "|   I told them th...|        Negative|[, , , i, told, t...|(65536,[1198,5660...|(65536,[1198,5660...|  1.0|\n",
      "|  A revised rail ...|        Positive|[, , a, revised, ...|(65536,[463,1032,...|(65536,[463,1032,...|  0.0|\n",
      "|  Add your favori...|        Positive|[, , add, your, f...|(65536,[19208,203...|(65536,[19208,203...|  0.0|\n",
      "|  COVID 19 UPDATE...|        Positive|[, , covid, 19, u...|(65536,[3856,4629...|(65536,[3856,4629...|  0.0|\n",
      "+--------------------+----------------+--------------------+--------------------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#transform model with validataion datasets\n",
    "val_df = pipelineFit.transform(val_set)\n",
    "train_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "862f1e20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://miro.medium.com/max/1400/1*YbUzYEjl4-asP1bSfXLSfw.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url= \"https://miro.medium.com/max/1400/1*YbUzYEjl4-asP1bSfXLSfw.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a5a58d",
   "metadata": {},
   "source": [
    "The execution of Multiclass grouping follows similar thoughts as the double characterization. As you probably are aware in paired arrangement, we tackle a yes or no issue. Like in the model in the previously mentioned article, the yield addressed the inquiry if an individual has coronary illness or not. We had just two classes: coronary illness and no coronary illness. \n",
    "\n",
    "If the yield is 1, the individual has coronary illness, and if the yield is 0 the individual doesn't have coronary illness. \n",
    "\n",
    "In multi-class grouping, we have multiple classes. Here is a model. Say, we have various components and qualities of vehicles, trucks, bicycles, and boats as information highlights. Our responsibility is to anticipate the label(postive,negative and impartial tweets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "91494a9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://raw.githubusercontent.com/ritchieng/machine-learning-stanford/master/w3_logistic_regression_regularization/logistic_regression.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url= \"https://raw.githubusercontent.com/ritchieng/machine-learning-stanford/master/w3_logistic_regression_regularization/logistic_regression.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "571f899e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic regression multiclass \n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "LR = LogisticRegression(maxIter=100)\n",
    "model = LR.fit(train_df)\n",
    "predictions = model.transform(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd33ddab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dummy testing data\n",
    "import pandas as pd\n",
    "test_data_sets = {\n",
    "    'OriginalTweet':[\n",
    "        \"i love to go shopping\",\n",
    "        'I hate the Master Chef US, its streaming this Friday on Fox #masterchef',\n",
    "        'i love cooking'\n",
    "    ]\n",
    "}\n",
    "\n",
    "test_result = pd.DataFrame(test_data_sets)\n",
    "\n",
    "test_result = sqlContext.createDataFrame(test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a7e3a3f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|       OriginalTweet|\n",
      "+--------------------+\n",
      "|i love to go shop...|\n",
      "|I hate the Master...|\n",
      "|      i love cooking|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8b3baf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predict(test_):\n",
    "    features = pipelineFit.transform(test_)\n",
    "    preds = model.transform(features)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dea36a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|prediction|\n",
      "+----------+\n",
      "|       0.0|\n",
      "|       1.0|\n",
      "|       0.0|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = model_predict(test_result)\n",
    "pred.select('prediction').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8851e38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
